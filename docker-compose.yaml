version: '3.8'

services:
  # =============================================================================
  # DATABASES
  # =============================================================================

  # Keycloak PostgreSQL Database
  keycloak_db:
    image: postgres:14
    container_name: keycloak_db
    environment:
      POSTGRES_DB: keycloak_db
      POSTGRES_USER: keycloak_user
      POSTGRES_PASSWORD: keycloak_password
    volumes:
      - keycloak_db_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U keycloak_user -d keycloak_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # CRM PostgreSQL Database (with CDC support)
  crm_db:
    image: postgres:14
    container_name: crm_db
    command: >
      postgres
      -c wal_level=logical
      -c max_wal_senders=4
      -c max_replication_slots=4
    environment:
      POSTGRES_DB: crm
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - crm_db_data:/var/lib/postgresql/data
      - ./db/crm-init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5434:5432"
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d crm"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Telemetry PostgreSQL Database
  telemetry_db:
    image: postgres:14
    container_name: telemetry_db
    environment:
      POSTGRES_DB: telemetry
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - telemetry_db_data:/var/lib/postgresql/data
      - ./db/telemetry-init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5435:5432"
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d telemetry"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =============================================================================
  # IDENTITY & ACCESS MANAGEMENT
  # =============================================================================

  # Keycloak IAM
  keycloak:
    image: quay.io/keycloak/keycloak:21.1
    container_name: keycloak
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://keycloak_db:5432/keycloak_db
      KC_DB_USERNAME: keycloak_user
      KC_DB_PASSWORD: keycloak_password
    command:
      - start-dev
      - --import-realm
    volumes:
      - ./keycloak/keycloak-results-export.json:/opt/keycloak/data/import/realm-export.json
    ports:
      - "8080:8080"
    depends_on:
      keycloak_db:
        condition: service_healthy
    networks:
      - bionicpro-network

  # OpenLDAP for international offices
  openldap:
    image: osixia/openldap:1.5.0
    container_name: openldap
    environment:
      LDAP_ORGANISATION: "BionicPRO"
      LDAP_DOMAIN: "example.com"
      LDAP_ADMIN_PASSWORD: "admin"
      LDAP_CONFIG_PASSWORD: "config"
    volumes:
      - ./ldap/config.ldif:/container/service/slapd/assets/config/bootstrap/ldif/custom/config.ldif
      - ldap_data:/var/lib/ldap
      - ldap_config:/etc/ldap/slapd.d
    ports:
      - "389:389"
      - "636:636"
    networks:
      - bionicpro-network
    command: --copy-service

  # =============================================================================
  # AUTH & API SERVICES
  # =============================================================================

  # Redis for session storage
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - bionicpro-network
    command: redis-server --appendonly yes

  # BionicPRO Auth Service
  bionicpro-auth:
    build:
      context: ./bionicpro-auth
      dockerfile: Dockerfile
    container_name: bionicpro-auth
    environment:
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_REALM: reports-realm
      KEYCLOAK_CLIENT_ID: bionicpro-auth
      KEYCLOAK_CLIENT_SECRET: bionicpro-auth-secret-key-12345
      REDIS_HOST: redis
      REDIS_PORT: 6379
      FRONTEND_URL: http://localhost:3000
      TOKEN_ENCRYPTION_KEY: your-32-byte-encryption-key-here!
      SESSION_TTL: 3600
      ACCESS_TOKEN_TTL: 120
    ports:
      - "8001:8001"
    depends_on:
      - keycloak
      - redis
    networks:
      - bionicpro-network

  # Reports API Service
  reports-api:
    build:
      context: ./reports-api
      dockerfile: Dockerfile
    container_name: reports-api
    environment:
      AUTH_SERVICE_URL: http://bionicpro-auth:8001
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: 9000
      CLICKHOUSE_DATABASE: bionicpro
      S3_ENDPOINT_URL: http://minio:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      S3_BUCKET: reports
      CDN_BASE_URL: http://localhost:8082
      FRONTEND_URL: http://localhost:3000
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_REALM: reports-realm
    ports:
      - "8000:8000"
    depends_on:
      - bionicpro-auth
      - clickhouse
      - minio
    networks:
      - bionicpro-network

  # =============================================================================
  # FRONTEND
  # =============================================================================

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    environment:
      REACT_APP_AUTH_URL: http://localhost:8001
      REACT_APP_API_URL: http://localhost:8000
      REACT_APP_KEYCLOAK_URL: http://localhost:8080
      REACT_APP_KEYCLOAK_REALM: reports-realm
      REACT_APP_KEYCLOAK_CLIENT_ID: reports-frontend
    ports:
      - "3000:3000"
    depends_on:
      - bionicpro-auth
      - reports-api
    networks:
      - bionicpro-network

  # =============================================================================
  # OLAP & ANALYTICS
  # =============================================================================

  # ClickHouse OLAP Database
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: clickhouse
    environment:
      CLICKHOUSE_DB: bionicpro
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ""
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native interface
    networks:
      - bionicpro-network
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  # =============================================================================
  # OBJECT STORAGE & CDN
  # =============================================================================

  # MinIO S3-compatible storage
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    ports:
      - "9090:9000"  # API
      - "9001:9001"  # Console
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Create MinIO bucket on startup
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb --ignore-existing myminio/reports;
      mc anonymous set download myminio/reports;
      exit 0;
      "
    networks:
      - bionicpro-network

  # Nginx CDN/Reverse Proxy
  nginx-cdn:
    image: nginx:alpine
    container_name: nginx-cdn
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - nginx_cache:/var/cache/nginx
    ports:
      - "8082:8082"
      - "80:80"
    depends_on:
      - minio
      - reports-api
      - bionicpro-auth
    networks:
      - bionicpro-network

  # =============================================================================
  # CDC PIPELINE (Kafka + Debezium)
  # =============================================================================

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    networks:
      - bionicpro-network

  # Kafka Message Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "29092:29092"
    networks:
      - bionicpro-network

  # Kafka Connect with Debezium
  kafka-connect:
    image: debezium/connect:2.4
    container_name: kafka-connect
    depends_on:
      - kafka
      - crm_db
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: bionicpro-connect
      CONFIG_STORAGE_TOPIC: bionicpro_connect_configs
      OFFSET_STORAGE_TOPIC: bionicpro_connect_offsets
      STATUS_STORAGE_TOPIC: bionicpro_connect_statuses
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
    volumes:
      - ./debezium:/debezium
    ports:
      - "8083:8083"
    networks:
      - bionicpro-network

  # =============================================================================
  # ETL (Apache Airflow)
  # =============================================================================

  airflow-postgres:
    image: postgres:14
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_db_data:/var/lib/postgresql/data
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.9.1-python3.9
    container_name: airflow-init
    depends_on:
      airflow-postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    command: bash -c "airflow db init && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@bionicpro.com --password admin"
    networks:
      - bionicpro-network

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.9
    container_name: airflow-webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__SECRET_KEY: 'airflow-webserver-secret-key'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    ports:
      - "8084:8080"
    command: webserver
    networks:
      - bionicpro-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.9
    container_name: airflow-scheduler
    depends_on:
      airflow-webserver:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    command: scheduler
    networks:
      - bionicpro-network

# =============================================================================
# VOLUMES
# =============================================================================

volumes:
  keycloak_db_data:
  crm_db_data:
  telemetry_db_data:
  clickhouse_data:
  minio_data:
  redis_data:
  ldap_data:
  ldap_config:
  kafka_data:
  zookeeper_data:
  zookeeper_log:
  airflow_db_data:
  nginx_cache:

# =============================================================================
# NETWORKS
# =============================================================================

networks:
  bionicpro-network:
    driver: bridge
